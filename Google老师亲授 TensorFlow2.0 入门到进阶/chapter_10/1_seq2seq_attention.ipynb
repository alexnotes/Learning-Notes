{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.1\n",
      "numpy 1.19.1\n",
      "pandas 1.1.3\n",
      "sklearn 0.23.2\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "# 1. preprocessing data\n",
    "# 2. build model\n",
    "# 2.1 encoder\n",
    "# 2.2 attention\n",
    "# 2.3 decoder\n",
    "# 2.4 loss & optimizer\n",
    "# 2.5 train\n",
    "# 3. evaluation\n",
    "# 3.1 given sentence, return translated results\n",
    "# 3.2 visualize results (attention)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May I borrow this book?\n",
      "¿Puedo tomar prestado este libro?\n",
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "# http://www.manythings.org/anki/\n",
    "# http://www.manythings.org/anki/spa-eng.zip\n",
    "en_spa_file_path = './spa.txt'\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    # NFD 是一种 normalize 方法，如果有一个 unicode 是由多个 ascii 组成的，\n",
    "    # 就将多个 ascii 拆开\n",
    "    # Mn 表示 重音。\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "\n",
    "print(unicode_to_ascii(en_sentence))\n",
    "print(unicode_to_ascii(sp_sentence))\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    # 标点符号前后加空格\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    #  多余的空格变成一个空格\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    # 除了标点符号和字母外都是空格\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    # 去掉前后空格\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "def parse_data(file_name):\n",
    "    lines = open(file_name, encoding='UTF-8').read().strip().split('\\n')\n",
    "    sentence_pairs = [line.split('\\t') for line in lines]\n",
    "    preprocessed_sentence_pairs = [\n",
    "        (preprocess_sentence(en), preprocess_sentence(sp)) for en, sp in sentence_pairs]\n",
    "    return zip(*preprocessed_sentence_pairs)\n",
    "\n",
    "en_dataset, sp_dataset = parse_data(en_spa_file_path)\n",
    "print(en_dataset[-1])\n",
    "print(sp_dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 5) (2, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "a = [(1, 2), (3, 4), (5, 6)]\n",
    "c, d = zip(*a)\n",
    "print(c, d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 11\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(lang):\n",
    "    lang_tokenizer = keras.preprocessing.text.Tokenizer(\n",
    "        num_words=None, filters='', split=' ')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = keras.preprocessing.sequence.pad_sequences(\n",
    "        tensor, padding='post')\n",
    "    return tensor, lang_tokenizer\n",
    "input_tensor, input_tokenizer = tokenizer(sp_dataset[0: 30000])\n",
    "output_tensor, output_tokenizer = tokenizer(en_dataset[0: 30000])\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "max_length_input = max_length(input_tensor)\n",
    "max_length_output = max_length(output_tensor)\n",
    "print(max_length_input, max_length_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 6000 24000 6000\n"
     ]
    }
   ],
   "source": [
    "input_train, input_eval, output_train, output_eval = train_test_split(\n",
    "    input_tensor, output_tensor, test_size=0.2)\n",
    "print(len(input_train), len(input_eval), len(output_train), len(output_eval))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> <start>\n",
      "1420 --> ensename\n",
      "94 --> algo\n",
      "103 --> nuevo\n",
      "3 --> .\n",
      "2 --> <end>\n",
      "\n",
      "1 --> <start>\n",
      "255 --> show\n",
      "17 --> me\n",
      "187 --> something\n",
      "146 --> new\n",
      "3 --> .\n",
      "2 --> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(example, tokenizer):\n",
    "    for t in example:\n",
    "        if t != 0:\n",
    "            print('%d --> %s' % (t, tokenizer.index_word[t]))\n",
    "convert(input_train[0], input_tokenizer)\n",
    "print()\n",
    "convert(output_train[0], output_tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def make_dataset(input_tensor, output_tensor, batch_size, epochs, shuffle):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(30000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "train_dataset = make_dataset(input_train, output_train, batch_size, epochs, True)\n",
    "eval_dataset = make_dataset(input_eval, output_eval, batch_size, epochs, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n",
      "(64, 11)\n",
      "tf.Tensor(\n",
      "[[   1 4057   33 ...    0    0    0]\n",
      " [   1    9   55 ...    0    0    0]\n",
      " [   1  178  171 ...    0    0    0]\n",
      " ...\n",
      " [   1    6  507 ...    0    0    0]\n",
      " [   1 1648   60 ...    0    0    0]\n",
      " [   1   51 3583 ...    0    0    0]], shape=(64, 16), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[   1  939   31  744  109    3    2    0    0    0    0]\n",
      " [   1   14   26 3696    3    2    0    0    0    0    0]\n",
      " [   1    4  130  123  102    3    2    0    0    0    0]\n",
      " [   1  178   25   86   41    3    2    0    0    0    0]\n",
      " [   1   13 2740 1280    3    2    0    0    0    0    0]\n",
      " [   1    4   38   64   44   10    3    2    0    0    0]\n",
      " [   1   14   11 1021    3    2    0    0    0    0    0]\n",
      " [   1    5 1235   61  168    3    2    0    0    0    0]\n",
      " [   1   32   29    6   76    7    2    0    0    0    0]\n",
      " [   1    4   77  665 4379    3    2    0    0    0    0]\n",
      " [   1   22    6   63   15   36    7    2    0    0    0]\n",
      " [   1  116    5  679   54   17    3    2    0    0    0]\n",
      " [   1   25   16  120   39    7    2    0    0    0    0]\n",
      " [   1   14  173   17    9  155  776    3    2    0    0]\n",
      " [   1    4  357   15   40 2104    3    2    0    0    0]\n",
      " [   1   13 1010  472  128    3    2    0    0    0    0]\n",
      " [   1   19    8  186    3    2    0    0    0    0    0]\n",
      " [   1   16   23  764  293    3    2    0    0    0    0]\n",
      " [   1    4   75  125  314  431    3    2    0    0    0]\n",
      " [   1    4  222   20   83    3    2    0    0    0    0]\n",
      " [   1  277   11    9 1143    3    2    0    0    0    0]\n",
      " [   1    4  161   13 1081    3    2    0    0    0    0]\n",
      " [   1   14  513    3    2    0    0    0    0    0    0]\n",
      " [   1   32   22  765  112    7    2    0    0    0    0]\n",
      " [   1    4   42   20   55  235    3    2    0    0    0]\n",
      " [   1    4   43   20  210    3    2    0    0    0    0]\n",
      " [   1   57   11   66 1058  110    3    2    0    0    0]\n",
      " [   1  584   49   30   12   36    3    2    0    0    0]\n",
      " [   1    5    8    9 1717    3    2    0    0    0    0]\n",
      " [   1    4  262   21  644  163  669    3    2    0    0]\n",
      " [   1    4   18 4728   15   45    3    2    0    0    0]\n",
      " [   1    4   18   79 2626    3    2    0    0    0    0]\n",
      " [   1   10   11  412    3    2    0    0    0    0    0]\n",
      " [   1  157  173   17   20    3    2    0    0    0    0]\n",
      " [   1   10   11   34   21  646    3    2    0    0    0]\n",
      " [   1   10  552    3    2    0    0    0    0    0    0]\n",
      " [   1    4  851   54   20    3    2    0    0    0    0]\n",
      " [   1   19    8   21 1471    3    2    0    0    0    0]\n",
      " [   1   14  307   21  312    3    2    0    0    0    0]\n",
      " [   1  157  399   80   17    3    2    0    0    0    0]\n",
      " [   1   14    8   48  232    3    2    0    0    0    0]\n",
      " [   1    5  905   15   45    3    2    0    0    0    0]\n",
      " [   1   14 1154  414    3    2    0    0    0    0    0]\n",
      " [   1   16   35   10    3    2    0    0    0    0    0]\n",
      " [   1   10    8  103   78  287    3    2    0    0    0]\n",
      " [   1   27  100   12  156   10    3    2    0    0    0]\n",
      " [   1   57   11   66 3606    3    2    0    0    0    0]\n",
      " [   1    4  222    9 2787    3    2    0    0    0    0]\n",
      " [   1   27  709   17    3    2    0    0    0    0    0]\n",
      " [   1  456   10   74   37    2    0    0    0    0    0]\n",
      " [   1   21 1591   35   17    3    2    0    0    0    0]\n",
      " [   1   28   23  876   15  295    3    2    0    0    0]\n",
      " [   1    5   38  309    3    2    0    0    0    0    0]\n",
      " [   1    5  216  232    3    2    0    0    0    0    0]\n",
      " [   1    4 3160   10   15   41    3    2    0    0    0]\n",
      " [   1   13 1662    8  948    3    2    0    0    0    0]\n",
      " [   1    6   23   21  469    3    2    0    0    0    0]\n",
      " [   1   13  467    8  197    3    2    0    0    0    0]\n",
      " [   1   20   11  741    3    2    0    0    0    0    0]\n",
      " [   1    4   96  219  109   36   58    3    2    0    0]\n",
      " [   1    4   18    9  303  275    3    2    0    0    0]\n",
      " [   1   32    8  208 4577  208    7    2    0    0    0]\n",
      " [   1  120   71    6   24    3    2    0    0    0    0]\n",
      " [   1    6   23  907   37    2    0    0    0    0    0]], shape=(64, 11), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x)\n",
    "    print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "embedding_units = 256\n",
    "units = 1024\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoding_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(self.encoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoding_units))\n",
    "    \n",
    "encoder = Encoder(input_vocab_size, embedding_units, units, batch_size)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(x, sample_hidden)\n",
    "\n",
    "print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, decoder_hidden, encoder_outputs):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        decoder_hidden_with_time_axis = tf.expand_dims(\n",
    "            decoder_hidden, 1)\n",
    "\n",
    "        # before V: (batch_size, length, units)\n",
    "        # after V: (batch_size, length, 1)\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(\n",
    "            tf.nn.tanh(\n",
    "                self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * encoder_outputs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (64, 4935)\n",
      "Decoder hidden shape: (64, 1024)\n",
      "Decoder attention weights shape: (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoding_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(self.decoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.decoding_units)\n",
    "\n",
    "    def call(self, x, hidden, encoding_output):\n",
    "        # context_vector.shape: (batch_size, units)\n",
    "        context_vector, attention_weights = self.attention(hidden, encoding_output)\n",
    "\n",
    "        # before embedding: x.shape: (batch_size, 1)\n",
    "        # after embedding: x.shape: (batch_size, 1, embedding_units)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # context_vector.shape: (batch_size, units)\n",
    "        # x.shape: (batch_size, 1, embedding_units)\n",
    "        # 两者的维度不一样，需要对 context_vector 进行维度扩展\n",
    "        # x shape after concatenation：\n",
    "        # (batch_size, 1, embedding_dim + hidden_size)\n",
    "        combined_x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # output.shape: [batch_size, 1, decoding_units]\n",
    "        # state.shape: [batch_size, decoding_units]\n",
    "        output, state = self.gru(combined_x)\n",
    "\n",
    "        # output.shape: [batch_size, decoding_units]\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape: [batch_size, vocab_size]\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, state, attention_weights\n",
    "\n",
    "decoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n",
    "outputs = decoder(tf.random.uniform((batch_size, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "decoder_output, decoder_hidden, decoder_aw = outputs\n",
    "print ('Decoder output shape: {}'.format(decoder_output.shape))\n",
    "print ('Decoder hidden shape: {}'.format(decoder_hidden.shape))\n",
    "print ('Decoder attention weights shape: {}'.format(decoder_aw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "# reduction：指明损失函数如何聚合\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # logical_not：取反\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # 由于 loss_  是 float 类型，需要对 mask 做一个类型变换\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "checkpoint_dir = './10-1_checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, encoding_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoding_outputs, encoding_hidden = encoder(inp, encoding_hidden)\n",
    "\n",
    "        decoding_hidden = encoding_hidden\n",
    "\n",
    "        # eg: <start> I am here <end>\n",
    "        # 1. <start> --> I\n",
    "        # 2. I --> am\n",
    "        # 3. am --> here\n",
    "        # 4. here --> <end>\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1] - 1):\n",
    "            decoding_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, decoding_hidden, _ = decoder(\n",
    "                decoding_input, decoding_hidden, encoding_outputs)\n",
    "\n",
    "            loss += loss_function(targ[:, t + 1], predictions)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[0]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.6561\n",
      "Epoch 1 Batch 100 Loss 0.3151\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-04f5a4b15490>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m         \u001B[0mbatch_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding_hidden\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0mtotal_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mbatch_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/TensorFlowTutorials/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 457\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    458\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtracing_count\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    459\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_counter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcalled_without_tracing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/TensorFlowTutorials/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    485\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    486\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 487\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    488\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    489\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/TensorFlowTutorials/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1821\u001B[0m     \u001B[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1822\u001B[0m     \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1823\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1824\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1825\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/TensorFlowTutorials/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   1139\u001B[0m          if isinstance(t, (ops.Tensor,\n\u001B[1;32m   1140\u001B[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001B[0;32m-> 1141\u001B[0;31m         self.captured_inputs)\n\u001B[0m\u001B[1;32m   1142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1143\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_flat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcancellation_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/TensorFlowTutorials/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1222\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1223\u001B[0m       flat_outputs = forward_function.call(\n\u001B[0;32m-> 1224\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001B[0m\u001B[1;32m   1225\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1226\u001B[0m       \u001B[0mgradient_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_delayed_rewrite_functions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/TensorFlowTutorials/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    509\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    510\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"executor_type\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexecutor_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"config_proto\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 511\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    512\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    513\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m~/anaconda3/envs/TensorFlowTutorials/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001B[1;32m     60\u001B[0m                                                \u001B[0mop_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m                                                num_outputs)\n\u001B[0m\u001B[1;32m     62\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(input_tensor) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    encoding_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, encoding_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                epoch + 1, batch, batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_sentence):\n",
    "    attention_matrix = np.zeros((max_length_output, max_length_input))\n",
    "    input_sentence = preprocess_sentence(input_sentence)\n",
    "\n",
    "    inputs = [input_tokenizer.word_index[i] for i in input_sentence.split(' ')]\n",
    "    inputs = keras.preprocessing.sequence.pad_sequences(\n",
    "        [inputs], maxlen=max_length_input, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    encoding_hidden = tf.zeros((1, units))\n",
    "\n",
    "    encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden)\n",
    "    decoding_hidden = encoding_hidden\n",
    "\n",
    "    # eg: <start> --> A\n",
    "    # A --> B --> C --> D\n",
    "    # decoding_input.shape: (1, 1)\n",
    "    decoding_input = tf.expand_dims([output_tokenizer.word_index['<start>']], 0)\n",
    "    for t in range(max_length_output):\n",
    "        predictions, decoding_hidden, attention_weights = decoder(\n",
    "            decoding_input, decoding_hidden, encoding_outputs)\n",
    "\n",
    "        # attention_weights.shape: (batch_size, input_length, 1) (1, 16, 1)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_matrix[t] = attention_weights.numpy()\n",
    "\n",
    "        # predictions.shape: (batch_size, vocab_size) (1, 4935)\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += output_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if output_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, input_sentence, attention_matrix\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        decoding_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, input_sentence, attention_matrix\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention_matrix, input_sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention_matrix, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + input_sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def translate(input_sentence):\n",
    "    result, input_sentence, attention_matrix = evaluate(input_sentence)\n",
    "\n",
    "    print('Input: %s' % (input_sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_matrix = attention_matrix[:len(result.split(' ')), :len(input_sentence.split(' '))]\n",
    "    plot_attention(attention_matrix, input_sentence.split(' '), result.split(' '))\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'¿todavia estan en casa?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'trata de averiguarlo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}